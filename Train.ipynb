{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from unet import UNet\n",
    "from preprocessing_1_dataloader import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Initialisation####\n",
    "#create 2 network\n",
    "Student = UNet(3,2)\n",
    "Teacher = UNet(3,2)\n",
    "#creat the losses\n",
    "sup_crit = nn.CrossEntropyLoss()\n",
    "unsup_crit = nn.CrossEntropyLoss()\n",
    "#optimizer\n",
    "optimizer = Adam(Student.parameters())\n",
    "#other HP\n",
    "batch_size = 64\n",
    "epochs = 16\n",
    "ramp_up = 10\n",
    "consistency = 56\n",
    "alpha = 0.999\n",
    "gs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weigth coef for the Unsupervised\n",
    "def wt(rampup_length, current, alpha):\n",
    "    if rampup_length == 0:\n",
    "                return 1.0\n",
    "    else:\n",
    "        current = np.clip(current, 0.0, rampup_length)\n",
    "        phase = 1.0 - current / rampup_length\n",
    "        return float(alpha * np.exp(-5.0 * phase * phase))\n",
    "#update the Teacher weigth\n",
    "def update_ema_variables(model, ema_model, alpha, global_step): \n",
    "    # Use the true average until the exponential average is more correct\n",
    "    alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "    for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n",
    "        ema_param.data.mul_(alpha).add_(1 - alpha, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/images'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m##data loader\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mixed_train_loader, val_loader, test_loader \u001b[39m=\u001b[39m get_data(\u001b[39m0.2\u001b[39;49m,\u001b[39m0.8\u001b[39;49m,\u001b[39m0.2\u001b[39;49m,\u001b[39m0.1\u001b[39;49m)\n",
      "File \u001b[0;32m/mnt/c/Users/tducr/Music/UCL/Term2/COMP0197/cousework/group/comp0197-cw2/preprocessing_1_dataloader.py:142\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(nb_labeled_data, nb_unlabeled_data, percentage_validation, percentage_test)\u001b[0m\n\u001b[1;32m    139\u001b[0m images_directory \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39m./data/images\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    140\u001b[0m masks_directory \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39m./data/annotations/trimaps\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 142\u001b[0m images_filenames \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(images_directory)))\n\u001b[1;32m    143\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mall images are = \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(images_filenames))\n\u001b[1;32m    145\u001b[0m correct_images_filenames \u001b[39m=\u001b[39m readable_images(images_filenames, images_directory)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/images'"
     ]
    }
   ],
   "source": [
    "##data loader\n",
    "mixed_train_loader, val_loader, test_loader = get_data(0.2,0.8,0.2,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    cum_loss = 0\n",
    "    for idx, (X,y) in enumerate(mixed_train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        pred_stud = Student(X)\n",
    "        pred_teach = Teacher(X)\n",
    "\n",
    "        # Find img with label\n",
    "        idx = [elem != -1 for elem in y[:, 0, 0, 0]] #If batchsize is the first dim\n",
    "\n",
    "        # Calculate supervised and unsupervised losses\n",
    "        Ls = sup_crit(pred_stud[idx], y[idx])\n",
    "        Lu = unsup_crit(pred_stud, pred_teach)\n",
    "        loss = Ls + Lu * wt(ramp_up, epoch, consistency)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        cum_loss += loss\n",
    "        gs += 1\n",
    "        update_ema_variables(Student, Teacher, alpha, gs)\n",
    "    print(f'Epoch {epoch} loss {cum_loss.item() / len(trainloader)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0197-cw1-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
