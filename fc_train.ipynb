{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do\n",
    " - debug to get it working!!!\n",
    " - Transform the student input/label and teacher input differently\n",
    " - concatenate the labelled data and unlabelled data for 1 forward pass\n",
    " - add dropout to the student model\n",
    " - Check what losses we should be using. I think we don't use crossentropy and we use different ones for Lu and Ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://github.com/milesial/Pytorch-UNet/blob/master/unet/unet_parts.py\n",
    "\n",
    "# Import the model\n",
    "from unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_above_below(y, below, above):\n",
    "    y1 = torch.where(y < below, 1, y)\n",
    "    y2 = torch.where(y > above, 1, y1)\n",
    "    return y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some temporary dataloader to check model works\n",
    "transform_size = (128, 128)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        ,transforms.Resize(transform_size, max_size=None)\n",
    "])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        ,transforms.Lambda(lambda y: transform_above_below(y, 0.005, 0.01))\n",
    "        ,transforms.Resize(transform_size, max_size=None)\n",
    "        ,transforms.Lambda(lambda y: torch.where(y < 0.5, 0, 1))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataloaders should be of the same length - check should be zero: 0\n"
     ]
    }
   ],
   "source": [
    "# Select params:\n",
    "batch_size = 4\n",
    "labelled_percent = 0.25\n",
    "\n",
    "\n",
    "pet_dataset = datasets.OxfordIIITPet('', transform=transform, target_transform=target_transform, download=True, target_types='segmentation')\n",
    "pet_dataset_label, pet_dataset_unlabel = torch.utils.data.random_split(pet_dataset, [labelled_percent, 1 - labelled_percent])\n",
    "\n",
    "labelled_n = len(pet_dataset_label)\n",
    "batch_size_label = int(batch_size * labelled_percent)\n",
    "batch_size_unlabel = batch_size - batch_size_label\n",
    "\n",
    "data_loader_label = torch.utils.data.DataLoader(pet_dataset_label,\n",
    "                                          batch_size=batch_size_label,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "data_loader_unlabel = torch.utils.data.DataLoader(pet_dataset_unlabel,\n",
    "                                          batch_size=batch_size_unlabel,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "print(f'dataloaders should be of the same length - check should be zero: {len(data_loader_label) - len(data_loader_unlabel)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m cum_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[39m# for idx, (X,y) in enumerate(trainloader):\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[39mfor\u001b[39;00m label_data, unlabel_data \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(data_loader_label, data_loader_unlabel):\n\u001b[1;32m     48\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     50\u001b[0m     \u001b[39m# --------------------------------\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[39m# label iteration\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[39m# --------------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/comp0197-cw1-pt-gpu/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/comp0197-cw1-pt-gpu/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/comp0197-cw1-pt-gpu/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1283\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/comp0197-cw1-pt-gpu/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1121\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/comp0197-cw1-pt-gpu/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/miniconda3/envs/comp0197-cw1-pt-gpu/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/comp0197-cw1-pt-gpu/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/comp0197-cw1-pt-gpu/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/comp0197-cw1-pt-gpu/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from unet import UNet\n",
    "\n",
    "####Initialisation####\n",
    "#create 2 network\n",
    "model_student = UNet(3,2)\n",
    "model_teacher = UNet(3,2)\n",
    "#creat the losses\n",
    "sup_crit = nn.CrossEntropyLoss()\n",
    "unsup_crit = nn.CrossEntropyLoss()\n",
    "#optimizer\n",
    "optimizer = Adam(model_student.parameters())\n",
    "#other HP\n",
    "epochs = 16\n",
    "ramp_up = 10\n",
    "consistency = 56\n",
    "alpha = 0.999\n",
    "gs = 0\n",
    "\n",
    "#Weigth coef for the Unsupervised\n",
    "def wt(rampup_length, current, alpha):\n",
    "    if rampup_length == 0:\n",
    "                return 1.0\n",
    "    else:\n",
    "        current = np.clip(current, 0.0, rampup_length)\n",
    "        phase = 1.0 - current / rampup_length\n",
    "        return float(alpha * np.exp(-5.0 * phase * phase))\n",
    "\n",
    "\n",
    "#update the model_teacher weigth\n",
    "def update_ema_variables(model, ema_model, alpha, global_step): \n",
    "    # Use the true average until the exponential average is more correct\n",
    "    alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "    for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n",
    "        ema_param.data.mul_(alpha).add_(1 - alpha, param.data)\n",
    "\n",
    "\n",
    "##data loader - now created in previous cells\n",
    "# trainloader = Data_Loader(batch_size=batch_size, shuffle=True)\n",
    "for epoch in range(epochs):\n",
    "    cum_loss = 0\n",
    "    # for idx, (X,y) in enumerate(trainloader):\n",
    "    for label_data, unlabel_data in zip(data_loader_label, data_loader_unlabel):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # --------------------------------\n",
    "        # label iteration\n",
    "        # --------------------------------\n",
    "        X, y = label_data\n",
    "        y = torch.squeeze(y)\n",
    "        pred_stud = model_student(X)\n",
    "        pred_teach = model_teacher(X)\n",
    "        print(f'y shape: {y.shape}')\n",
    "        print(f'student output shape: {pred_stud.shape}')\n",
    "\n",
    "        # Calculate supervised and unsupervised losses\n",
    "        Ls = sup_crit(pred_stud[80:], y[80:])\n",
    "        Lu = unsup_crit(pred_stud, pred_teach)\n",
    "        loss = Ls + Lu * wt(ramp_up, epoch, consistency)\n",
    "        \n",
    "        \n",
    "        # --------------------------------\n",
    "        # unlabel iteration\n",
    "        # --------------------------------\n",
    "        X, y = unlabel_data\n",
    "        y = torch.squeeze(y)\n",
    "        pred_stud = model_student(X)\n",
    "        pred_teach = model_teacher(X)\n",
    "\n",
    "        # Calculate only unsupervised losses\n",
    "        Lu = unsup_crit(pred_stud, pred_teach)\n",
    "        loss += Lu * wt(ramp_up, epoch, consistency)\n",
    "        \n",
    "        \n",
    "        # --------------------------------\n",
    "        # update weights\n",
    "        # --------------------------------\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        cum_loss += loss\n",
    "        gs += 1\n",
    "        update_ema_variables(model_student, model_teacher, alpha, gs)\n",
    "        print(f'global step: {gs:10d}')\n",
    "    print(f'Epoch {epoch:2d} loss {(loss.item() / y.shape[0]):7.3f}')\n",
    "                \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0197-cw1-pt-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10b77cd3e758c5cae7cf43d6678d201973fa77fb3a7bd02539f4da1babd23f0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
