{"cells":[{"cell_type":"markdown","source":["This notebook can be ONLY used for:\n","\n","1. Calculating the performance **upper bound: change pct_data = 1**.\n","2. Calculating the performance **lower bound: change pct_data = supervised data %**.\n","\n","Make sure to add whatever file path you think will be more convinient. In my case, for each model I created a folder, and 3 subfolders, one for the LB, UP and Mean Teacher. If you choose this method, **make sure the folders are created beforehand**. Otherwise, feel free to do whatever. For this notebook, the following things will be saved: \n","\n","1. The weights of the model every 5 epochs (./whatever_name_you_want_epoch_X). \n","2. Running loss during training (every epoch).\n","3. Accuracy and IOU on train set every 5 epochs.\n","4. Accuracy and IOU on validation set every 5 epochs.\n","\n","**If you use this notebook directly from colab, PLEASE make a copy and don't change anything in the original file, cuz then my kernel will crash :(**.\n","\n","**NOTE: This file uses a modified version of the dataloader in GitHub. If you run it with that one you will get an attribute error from get_data.**"],"metadata":{"id":"50lZr0KBB-b0"}},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1680177292156,"user":{"displayName":"Marta Emili","userId":"12355713369317347230"},"user_tz":-60},"id":"UqQWZ0boJSHq"},"outputs":[],"source":["# ONLY PARAMETER THAT SHOULD BE CHANGED. \n","pct_data = 0.4 # Total amount of data the model will see. This is to calculate the LB (or UB) for the performance of the model. All labeled.\n","model_save_path = \"./M2_29_03_23/M2_LB/\""]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17638,"status":"ok","timestamp":1680177309789,"user":{"displayName":"Marta Emili","userId":"12355713369317347230"},"user_tz":-60},"id":"fIQq0PppFAcW","outputId":"460d0be2-5706-494c-e20f-369ce26db2ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1680177309789,"user":{"displayName":"Marta Emili","userId":"12355713369317347230"},"user_tz":-60},"id":"fUN1BvDDJJio","outputId":"c58230f2-aae1-44d7-f490-55bc13d7da8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mgdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}],"source":["%ls"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1680177309790,"user":{"displayName":"Marta Emili","userId":"12355713369317347230"},"user_tz":-60},"id":"_isQRcwlFEGr","outputId":"429910b5-1a34-49eb-971a-0d15a9ceb9e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Applied DL CW\n"]}],"source":["%cd /content/gdrive/MyDrive/Applied DL CW"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":419,"status":"ok","timestamp":1680177310205,"user":{"displayName":"Marta Emili","userId":"12355713369317347230"},"user_tz":-60},"id":"Klw1e4jWIg7j","outputId":"24588539-9adc-43ef-9016-ec8df01d6336"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdata\u001b[0m/                 \u001b[01;34mM1_28_03_23\u001b[0m/   \u001b[01;34m__pycache__\u001b[0m/              utils.py\n","data_augmentation.py  \u001b[01;34mM2_29_03_23\u001b[0m/   Train_Mean_Teacher.ipynb\n","data_into_loaders.py  model_UNet.py  Train_Supervised.ipynb\n"]}],"source":["%ls"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3776,"status":"ok","timestamp":1680177313980,"user":{"displayName":"Marta Emili","userId":"12355713369317347230"},"user_tz":-60},"id":"OldzXbtYFG7H"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import Adam, lr_scheduler\n","import model_UNet\n","from data_augmentation import augmentation, colorjiter, invert\n","import matplotlib.pyplot as plt\n","from data_into_loaders import get_data\n","from utils import dice_loss, wt, update_ema_variables, unsup_loss, evaluate_model"]},{"cell_type":"code","source":["#### Do NOT touch these hyperparameters\n","img_resize = 64\n","depth, dropout_rate = 3, 0.25 # Depth of U-Net\n","val_pct, test_pct = 0.2, 0.1 #Â Validation and test set %. \n","\n","# Trainin params\n","batch_size = 32\n","epochs = 100\n","lr, lr_gamma = 1e-3, 0.9 #Optimizer params\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n","print(f'Using device: {device}')"],"metadata":{"id":"A0SECf4q_gdf","executionInfo":{"status":"ok","timestamp":1680176400381,"user_tz":-60,"elapsed":9,"user":{"displayName":"Marta Emili","userId":"12355713369317347230"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1cfa4d36-865f-46f1-ff56-434d64e480c0"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda:0\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q7NLvKzoFAca","executionInfo":{"status":"ok","timestamp":1680176405640,"user_tz":-60,"elapsed":5263,"user":{"displayName":"Marta Emili","userId":"12355713369317347230"}},"outputId":"48e211b9-2aae-47b5-9149-4d9d29b51843"},"outputs":[{"output_type":"stream","name":"stderr","text":["/content/gdrive/MyDrive/Applied DL CW/model_UNet.py:211: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  init.xavier_normal(m.weight)\n","/content/gdrive/MyDrive/Applied DL CW/model_UNet.py:212: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  init.constant(m.bias, 0)\n"]},{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.0000e-03.\n"]}],"source":["# Initialize models, losses and optimizers. Make sure to re-run this cell again if you stop training and start again\n","#Create 1 network\n","modelS = model_UNet.UNet(in_channels=3, num_classes=2, depth=depth)\n","modelS= modelS.to(device)\n","\n","#optimizer\n","optimizer = Adam(modelS.parameters(), lr=lr)\n","scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=lr_gamma, last_epoch=-1, verbose=True)"]},{"cell_type":"code","source":["mixed_train_loader, val_loader, test_loader = get_data(0.25,0.75,val_pct, test_pct, batch_size=batch_size, img_resize=img_resize, is_mixed_loader = False, pct_data = pct_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ioDEeRRtjYLO","executionInfo":{"status":"ok","timestamp":1680176762724,"user_tz":-60,"elapsed":66367,"user":{"displayName":"Marta Emili","userId":"12355713369317347230"}},"outputId":"037ed41f-3732-4cf5-9123-780ac18b25d7"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["all images are =  7393\n","There are 7377 images.\n","There are 2065 train images, 1475 validation and 739 test\n"]}]},{"cell_type":"code","execution_count":10,"metadata":{"id":"cn4t1ijbFAcb","colab":{"base_uri":"https://localhost:8080/","height":407},"outputId":"6d06f40d-13c4-415a-91df-a423950e34ea","executionInfo":{"status":"error","timestamp":1680175715566,"user_tz":-60,"elapsed":1128310,"user":{"displayName":"Marta Emili","userId":"12355713369317347230"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch:    1 - Loss:  17.81\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-892420229afb>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m           \u001b[0;31m# Get accuracy and IOU for train and validation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m           \u001b[0maccTr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIouTr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixed_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m           \u001b[0maccVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIouVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m           \u001b[0maccsTr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccTr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/MyDrive/Applied DL CW/utils.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0mpixel_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixel_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/MyDrive/Applied DL CW/data_into_loaders.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mimage_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages_filenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         mask = Image.open(\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasks_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_filename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2982\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2984\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2986\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Train\n","eval_freq = 5\n","losses, accsTr, IousTr, accsVal, IousVal = [], [], [], [], []\n","\n","for epoch in range(epochs):\n","\n","        modelS.train()\n","        running_loss = 0\n","\n","        for step, data in enumerate(mixed_train_loader):\n","\n","            imgs, labs = data\n","            # Augment images\n","            imgS_aug = augmentation(imgs)\n","\n","            imgS_aug = imgS_aug.to(device)\n","            labs = labs.squeeze().type(torch.LongTensor).to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Forward pass for student and teacher\n","            z = modelS(imgS_aug) \n","            loss = dice_loss(z, labs)\n","            \n","            loss.backward()\n","            \n","            optimizer.step()    \n","            running_loss += loss.item()\n","\n","\n","        print(f'Epoch: {epoch + 1:4d} - Loss: {running_loss:6.2f}')\n","        losses.append(running_loss)\n","    \n","        if (epoch % eval_freq == 0):\n","\n","          # Get accuracy and IOU for train and validation dataset \n","          accTr, IouTr = evaluate_model(modelS, mixed_train_loader, device)\n","          accVal, IouVal = evaluate_model(modelS, val_loader, device)\n","          \n","          accsTr.append(accTr)\n","          IousTr.append(IouTr)   \n","          accsVal.append(accVal)\n","          IousVal.append(IouVal)\n","\n","          print(f'For training: accuracy-{accTr:2.0%}; IOU-{IouTr:2.0%}')\n","          print(f'For validation: accuracy-{accVal:2.0%}; IOU-{IouVal:2.0%}')\n","\n","          np.savetxt(f\"{model_save_path}running_loss\", losses)\n","          np.savetxt(f\"{model_save_path}train_accuracy\", accsTr)\n","          np.savetxt(f\"{model_save_path}train_IOU\", IousTr)\n","          np.savetxt(f\"{model_save_path}val_accuracy\", accsVal)\n","          np.savetxt(f\"{model_save_path}val_IOU\", IousVal)\n","\n","          torch.save(modelS.state_dict(), f\"{model_save_path}model_epoch_{epoch+1}\" + '.pt')\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"comp0197-cw1-pt","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}